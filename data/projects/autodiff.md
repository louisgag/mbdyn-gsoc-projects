Automatic differentiation is a technique for generating the Jacobian matrix automatically, needed for the nonlinear solver, given the information of the residual vector which is coded in C++ language. At the moment almost all elements in MBDyn are using a hand-written contribution to the Jacobian matrix. That approach is time consuming, error prone and difficult to maintain. In addition to that, there is no easy way to check for the correctness of the Jacobian matrix.

Automatic differentiation is also implemented in MBDyn but it is still less efficient in terms of CPU time and size of generated machine code.

- Perform different benchmarks with open source template meta programming libraries for the matrix/vector domain like blitz++, armadillo and eigen3 and also for the scalar (automatic differentiation) domain like Adolc and CppAD.
Check also for recent papers in the area of automatic differentiation and template meta programming (e.g. on [www.autodiff.org](http://www.autodiff.org)).
Create a report about the techniques those libraries are using (aliasing, lazy evaluation, common sub-expressions, order of memory access, code generation, or just in time code generation, tape mode or tapeless mode, sparse Jacobians). That report also should show how efficient those libraries are in comparison to our current implementation in terms of CPU time and code size. In addition to that it should show how hardware techniques like vectorization (sse/avx) and intrinsic functions of compilers are exploited.
- Use a different approach for evaluation of template meta expressions: Instead of scalar domain template meta programs and matrix/vector domain template meta programs, only one domain should be used in order to make it easier for the compiler to optimise the code in terms of CPU time and size of machine code. Make use of the most promising techniques from 1) for the implementation. This part is probably the most difficult task because large parts of the existing library have to be redesigned.
However a prototype implementation, which covers the most critical operation, namely the matrix-matrix products, is available and performs even better than equivalent Fortran code.
The following topics should be considered:
 - Not all loops should be unrolled in order to reduce code size. In that way the instruction cache should be used less intensively and stall conditions of the CPU should be avoided.
 - Add support for matrices and vectors with dynamic size.
 - Automatically create temporary results for sub-expressions which are evaluated more than once.
 - Implement a simple “cost model” in order to decide whether to create a temporary sub-expression or not.
 - Use sequential memory access whenever possible.
 - Use explicit vectorization for all derivatives and also for matrix vector products if the compiler supports it.
 - Check for aliasing at compile time or at least at runtime. If runtime checking is required, checks should be done in debug mode only.
 - Check if the \_\_restrict\_\_ keyword of C++ can help to improve performance.
 - Perform benchmarks with Fortran code generated by automatic differentiation by source code transformation at different optimization levels (-O2, -O3, -Os).
